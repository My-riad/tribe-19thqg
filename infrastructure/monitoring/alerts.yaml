# ServiceAccount for Alertmanager to access Kubernetes resources
apiVersion: v1
kind: ServiceAccount
metadata:
  name: alertmanager
  namespace: monitoring
  labels:
    app: alertmanager
    part-of: tribe
    tier: observability

---
# ConfigMap containing Alertmanager configuration
apiVersion: v1
kind: ConfigMap
metadata:
  name: alertmanager-config
  namespace: monitoring
  labels:
    app: alertmanager
    part-of: tribe
    tier: observability
data:
  alertmanager.yml: |
    global:
      resolve_timeout: 5m
      slack_api_url: '${SLACK_WEBHOOK_URL}'
      smtp_smarthost: '${SMTP_SMARTHOST}'
      smtp_from: '${SMTP_FROM}'
      smtp_auth_username: '${SMTP_USERNAME}'
      smtp_auth_password: '${SMTP_PASSWORD}'
      smtp_require_tls: true
      pagerduty_url: 'https://events.pagerduty.com/v2/enqueue'

    templates:
      - '/etc/alertmanager/templates/*.tmpl'

    route:
      receiver: 'slack-notifications'
      group_by: ['alertname', 'service', 'severity']
      group_wait: 30s
      group_interval: 5m
      repeat_interval: 4h

      routes:
      - match:
          severity: critical
        receiver: 'pagerduty-critical'
        continue: true
        group_wait: 30s
        group_interval: 1m
        repeat_interval: 30m

      - match:
          severity: critical
          service: api-gateway
        receiver: 'pagerduty-api-team'
        group_wait: 30s
        group_interval: 1m
        repeat_interval: 30m

      - match:
          severity: critical
          service: ai-orchestration-service
        receiver: 'pagerduty-ai-team'
        group_wait: 30s
        group_interval: 1m
        repeat_interval: 30m

      - match:
          severity: critical
          service: matching-service
        receiver: 'pagerduty-ai-team'
        group_wait: 30s
        group_interval: 1m
        repeat_interval: 30m

      - match:
          severity: critical
          service: ~(api-gateway|ai-orchestration-service|matching-service)
        receiver: 'pagerduty-backend-team'
        group_wait: 30s
        group_interval: 1m
        repeat_interval: 30m

      - match:
          severity: warning
        receiver: 'slack-warnings'
        group_wait: 1m
        group_interval: 5m
        repeat_interval: 1h

      - match:
          severity: warning
          service: ~(node|kubernetes|monitoring)
        receiver: 'email-dev-team'
        group_wait: 5m
        group_interval: 15m
        repeat_interval: 2h

      - match:
          severity: info
        receiver: 'slack-info'
        group_wait: 1m
        group_interval: 5m
        repeat_interval: 4h

    inhibit_rules:
      - source_match:
          severity: 'critical'
        target_match:
          severity: 'warning'
        equal: ['alertname', 'service']

      - source_match:
          severity: 'warning'
        target_match:
          severity: 'info'
        equal: ['alertname', 'service']

    receivers:
      - name: 'slack-notifications'
        slack_configs:
        - channel: '#monitoring-alerts'
          send_resolved: true
          title: '[{{ .Status | toUpper }}{{ if eq .Status "firing" }}:{{ .Alerts.Firing | len }}{{ end }}] {{ .CommonLabels.alertname }}'
          text: >-
            {{ range .Alerts }}
            *Alert:* {{ .Annotations.summary }}
            *Description:* {{ .Annotations.description }}
            *Severity:* {{ .Labels.severity }}
            *Service:* {{ .Labels.service }}
            {{ if ne .Labels.instance "" }}*Instance:* {{ .Labels.instance }}{{ end }}
            {{ end }}

      - name: 'slack-warnings'
        slack_configs:
        - channel: '#monitoring-warnings'
          send_resolved: true
          title: '[{{ .Status | toUpper }}{{ if eq .Status "firing" }}:{{ .Alerts.Firing | len }}{{ end }}] {{ .CommonLabels.alertname }}'
          text: >-
            {{ range .Alerts }}
            *Alert:* {{ .Annotations.summary }}
            *Description:* {{ .Annotations.description }}
            *Severity:* {{ .Labels.severity }}
            *Service:* {{ .Labels.service }}
            {{ if ne .Labels.instance "" }}*Instance:* {{ .Labels.instance }}{{ end }}
            {{ end }}

      - name: 'slack-info'
        slack_configs:
        - channel: '#monitoring-info'
          send_resolved: true
          title: '[{{ .Status | toUpper }}{{ if eq .Status "firing" }}:{{ .Alerts.Firing | len }}{{ end }}] {{ .CommonLabels.alertname }}'
          text: >-
            {{ range .Alerts }}
            *Alert:* {{ .Annotations.summary }}
            *Description:* {{ .Annotations.description }}
            *Severity:* {{ .Labels.severity }}
            *Service:* {{ .Labels.service }}
            {{ if ne .Labels.instance "" }}*Instance:* {{ .Labels.instance }}{{ end }}
            {{ end }}

      - name: 'pagerduty-critical'
        pagerduty_configs:
        - service_key: '${PAGERDUTY_SERVICE_KEY_CRITICAL}'
          send_resolved: true
          description: '{{ .CommonLabels.alertname }}'
          details:
            summary: '{{ .CommonAnnotations.summary }}'
            description: '{{ .CommonAnnotations.description }}'
            severity: '{{ .CommonLabels.severity }}'
            service: '{{ .CommonLabels.service }}'

      - name: 'pagerduty-api-team'
        pagerduty_configs:
        - service_key: '${PAGERDUTY_SERVICE_KEY_API_TEAM}'
          send_resolved: true
          description: '{{ .CommonLabels.alertname }}'
          details:
            summary: '{{ .CommonAnnotations.summary }}'
            description: '{{ .CommonAnnotations.description }}'
            severity: '{{ .CommonLabels.severity }}'
            service: '{{ .CommonLabels.service }}'

      - name: 'pagerduty-ai-team'
        pagerduty_configs:
        - service_key: '${PAGERDUTY_SERVICE_KEY_AI_TEAM}'
          send_resolved: true
          description: '{{ .CommonLabels.alertname }}'
          details:
            summary: '{{ .CommonAnnotations.summary }}'
            description: '{{ .CommonAnnotations.description }}'
            severity: '{{ .CommonLabels.severity }}'
            service: '{{ .CommonLabels.service }}'

      - name: 'pagerduty-backend-team'
        pagerduty_configs:
        - service_key: '${PAGERDUTY_SERVICE_KEY_BACKEND_TEAM}'
          send_resolved: true
          description: '{{ .CommonLabels.alertname }}'
          details:
            summary: '{{ .CommonAnnotations.summary }}'
            description: '{{ .CommonAnnotations.description }}'
            severity: '{{ .CommonLabels.severity }}'
            service: '{{ .CommonLabels.service }}'

      - name: 'email-dev-team'
        email_configs:
        - to: '${EMAIL_DEV_TEAM}'
          send_resolved: true
          headers:
            subject: '[{{ .Status | toUpper }}] {{ .CommonLabels.alertname }}'
          html: |
            <h2>{{ .CommonLabels.alertname }}</h2>
            <p><strong>Status:</strong> {{ .Status }}</p>
            <p><strong>Severity:</strong> {{ .CommonLabels.severity }}</p>
            <p><strong>Service:</strong> {{ .CommonLabels.service }}</p>
            <p><strong>Summary:</strong> {{ .CommonAnnotations.summary }}</p>
            <p><strong>Description:</strong> {{ .CommonAnnotations.description }}</p>
            {{ if ne .CommonLabels.instance "" }}
            <p><strong>Instance:</strong> {{ .CommonLabels.instance }}</p>
            {{ end }}
            <hr>
            <p><small>Sent by Alertmanager</small></p>

---
# ConfigMap containing Alertmanager notification templates
apiVersion: v1
kind: ConfigMap
metadata:
  name: alertmanager-templates
  namespace: monitoring
  labels:
    app: alertmanager
    part-of: tribe
    tier: observability
data:
  default.tmpl: |
    {{ define "__alertmanager" }}AlertManager{{ end }}
    {{ define "__alertmanagerURL" }}{{ .ExternalURL }}/#/alerts?receiver={{ .Receiver | urlquery }}{{ end }}

    {{ define "tribe.title" }}
    [{{ .Status | toUpper }}{{ if eq .Status "firing" }}:{{ .Alerts.Firing | len }}{{ end }}] {{ .CommonLabels.alertname }}
    {{ end }}

    {{ define "tribe.text" }}
    {{ range .Alerts }}
    *Alert:* {{ .Annotations.summary }}
    *Description:* {{ .Annotations.description }}
    *Severity:* {{ .Labels.severity }}
    *Service:* {{ .Labels.service }}
    {{ if ne .Labels.instance "" }}*Instance:* {{ .Labels.instance }}{{ end }}
    {{ end }}
    {{ end }}

    {{ define "tribe.email.html" }}
    <!DOCTYPE html>
    <html>
    <head>
      <meta charset="UTF-8">
      <title>{{ template "tribe.title" . }}</title>
      <style>
        body {
          font-family: Arial, sans-serif;
          margin: 0;
          padding: 20px;
          color: #333;
        }
        h2 {
          color: {{ if eq .Status "firing" }}#cc0000{{ else }}#009900{{ end }};
          margin-top: 0;
        }
        .alert {
          margin-bottom: 20px;
          padding: 15px;
          border-left: 5px solid {{ if eq .Status "firing" }}#cc0000{{ else }}#009900{{ end }};
          background-color: #f9f9f9;
        }
        .alert-info {
          margin-bottom: 10px;
        }
        .alert-info strong {
          display: inline-block;
          width: 100px;
        }
        .footer {
          margin-top: 20px;
          font-size: 12px;
          color: #999;
        }
      </style>
    </head>
    <body>
      <h2>{{ template "tribe.title" . }}</h2>
      
      {{ range .Alerts }}
      <div class="alert">
        <div class="alert-info"><strong>Alert:</strong> {{ .Annotations.summary }}</div>
        <div class="alert-info"><strong>Description:</strong> {{ .Annotations.description }}</div>
        <div class="alert-info"><strong>Severity:</strong> {{ .Labels.severity }}</div>
        <div class="alert-info"><strong>Service:</strong> {{ .Labels.service }}</div>
        {{ if ne .Labels.instance "" }}
        <div class="alert-info"><strong>Instance:</strong> {{ .Labels.instance }}</div>
        {{ end }}
        <div class="alert-info"><strong>Started:</strong> {{ .StartsAt.Format "2006-01-02 15:04:05 MST" }}</div>
      </div>
      {{ end }}
      
      <div class="footer">
        <p>This alert was sent by the Tribe monitoring system.</p>
        <p>View in <a href="{{ .ExternalURL }}">Alertmanager</a></p>
      </div>
    </body>
    </html>
    {{ end }}

---
# PersistentVolumeClaim for Alertmanager data storage
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: alertmanager-storage
  namespace: monitoring
  labels:
    app: alertmanager
    part-of: tribe
    tier: observability
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 1Gi
  storageClassName: gp2

---
# Deployment for Alertmanager alert notification service
apiVersion: apps/v1
kind: Deployment
metadata:
  name: alertmanager
  namespace: monitoring
  labels:
    app: alertmanager
    part-of: tribe
    tier: observability
spec:
  replicas: 1
  selector:
    matchLabels:
      app: alertmanager
  strategy:
    type: Recreate
  template:
    metadata:
      labels:
        app: alertmanager
        part-of: tribe
        tier: observability
      annotations:
        prometheus.io/scrape: "true"
        prometheus.io/port: "9093"
    spec:
      serviceAccountName: alertmanager
      securityContext:
        fsGroup: 65534
        runAsGroup: 65534
        runAsNonRoot: true
        runAsUser: 65534
      containers:
        - name: alertmanager
          image: prom/alertmanager:v0.25.0
          imagePullPolicy: IfNotPresent
          args:
            - --config.file=/etc/alertmanager/alertmanager.yml
            - --storage.path=/alertmanager
            - --web.external-url=https://monitoring.${DOMAIN_NAME}/alertmanager
            - --web.route-prefix=/alertmanager
            - --cluster.listen-address=0.0.0.0:9094
          ports:
            - name: http
              containerPort: 9093
              protocol: TCP
            - name: cluster
              containerPort: 9094
              protocol: TCP
          readinessProbe:
            httpGet:
              path: /-/ready
              port: 9093
            initialDelaySeconds: 30
            timeoutSeconds: 5
          livenessProbe:
            httpGet:
              path: /-/healthy
              port: 9093
            initialDelaySeconds: 30
            timeoutSeconds: 5
          resources:
            requests:
              cpu: 100m
              memory: 128Mi
            limits:
              cpu: 200m
              memory: 256Mi
          volumeMounts:
            - name: config
              mountPath: /etc/alertmanager/alertmanager.yml
              subPath: alertmanager.yml
            - name: templates
              mountPath: /etc/alertmanager/templates
            - name: storage
              mountPath: /alertmanager
          env:
            - name: SLACK_WEBHOOK_URL
              valueFrom:
                secretKeyRef:
                  name: alertmanager-secrets
                  key: slack-webhook-url
            - name: SMTP_SMARTHOST
              valueFrom:
                secretKeyRef:
                  name: alertmanager-secrets
                  key: smtp-smarthost
            - name: SMTP_FROM
              valueFrom:
                secretKeyRef:
                  name: alertmanager-secrets
                  key: smtp-from
            - name: SMTP_USERNAME
              valueFrom:
                secretKeyRef:
                  name: alertmanager-secrets
                  key: smtp-username
            - name: SMTP_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: alertmanager-secrets
                  key: smtp-password
            - name: PAGERDUTY_SERVICE_KEY_CRITICAL
              valueFrom:
                secretKeyRef:
                  name: alertmanager-secrets
                  key: pagerduty-service-key-critical
            - name: PAGERDUTY_SERVICE_KEY_API_TEAM
              valueFrom:
                secretKeyRef:
                  name: alertmanager-secrets
                  key: pagerduty-service-key-api-team
            - name: PAGERDUTY_SERVICE_KEY_AI_TEAM
              valueFrom:
                secretKeyRef:
                  name: alertmanager-secrets
                  key: pagerduty-service-key-ai-team
            - name: PAGERDUTY_SERVICE_KEY_BACKEND_TEAM
              valueFrom:
                secretKeyRef:
                  name: alertmanager-secrets
                  key: pagerduty-service-key-backend-team
            - name: EMAIL_DEV_TEAM
              valueFrom:
                secretKeyRef:
                  name: alertmanager-secrets
                  key: email-dev-team
      volumes:
        - name: config
          configMap:
            name: alertmanager-config
        - name: templates
          configMap:
            name: alertmanager-templates
        - name: storage
          persistentVolumeClaim:
            claimName: alertmanager-storage

---
# Service to expose Alertmanager within the cluster
apiVersion: v1
kind: Service
metadata:
  name: alertmanager
  namespace: monitoring
  labels:
    app: alertmanager
    part-of: tribe
    tier: observability
  annotations:
    prometheus.io/scrape: "true"
    prometheus.io/port: "9093"
spec:
  selector:
    app: alertmanager
  ports:
    - name: http
      port: 9093
      targetPort: 9093
      protocol: TCP
    - name: cluster
      port: 9094
      targetPort: 9094
      protocol: TCP

---
# Secret containing sensitive configuration for Alertmanager
apiVersion: v1
kind: Secret
metadata:
  name: alertmanager-secrets
  namespace: monitoring
  labels:
    app: alertmanager
    part-of: tribe
    tier: observability
type: Opaque
stringData:
  slack-webhook-url: ${SLACK_WEBHOOK_URL}
  smtp-smarthost: ${SMTP_SMARTHOST}
  smtp-from: ${SMTP_FROM}
  smtp-username: ${SMTP_USERNAME}
  smtp-password: ${SMTP_PASSWORD}
  pagerduty-service-key-critical: ${PAGERDUTY_SERVICE_KEY_CRITICAL}
  pagerduty-service-key-api-team: ${PAGERDUTY_SERVICE_KEY_API_TEAM}
  pagerduty-service-key-ai-team: ${PAGERDUTY_SERVICE_KEY_AI_TEAM}
  pagerduty-service-key-backend-team: ${PAGERDUTY_SERVICE_KEY_BACKEND_TEAM}
  email-dev-team: ${EMAIL_DEV_TEAM}